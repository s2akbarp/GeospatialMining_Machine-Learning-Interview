{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core ML Concepts\n",
    "\n",
    "In machine learning, mastering fundamental models and algorithms is essential. Below, you'll find 50 core ML concepts that you can implement from scratch to deepen your understanding:\n",
    "\n",
    "1. **Linear Regression:** Predicts continuous values based on linear relationships in data.\n",
    "2. **Logistic Regression:** Classifies data using a logistic function for binary outcomes.\n",
    "3. **Decision Tree:** Hierarchical structure for decision-making based on feature splits.\n",
    "4. **Random Forest:** Ensemble learning method using multiple decision trees for robust predictions.\n",
    "5. **Support Vector Machine (SVM):** Finds an optimal hyperplane to separate classes in high-dimensional space.\n",
    "6. **K-Nearest Neighbors (KNN):** Classifies objects based on closest training examples in feature space.\n",
    "7. **K-Means Clustering:** Divides data into k clusters based on similarity.\n",
    "8. **DBSCAN:** Clustering algorithm based on density of points in space.\n",
    "9. **Hierarchical Clustering:** Builds clusters by merging or splitting based on proximity.\n",
    "10. **Gradient Boosting:** Combines weak learners sequentially to minimize loss.\n",
    "11. **XGBoost:** Optimized gradient boosting framework for speed and performance.\n",
    "12. **LightGBM:** Gradient boosting framework designed for large-scale data.\n",
    "13. **CatBoost:** Gradient boosting library optimized for categorical data.\n",
    "14. **Neural Network:** Deep learning model inspired by biological neural networks.\n",
    "15. **Convolutional Neural Network (CNN):** Deep learning model for processing grid-like data, such as images.\n",
    "16. **Recurrent Neural Network (RNN):** Designed for sequence prediction tasks using feedback loops.\n",
    "17. **Long Short-Term Memory (LSTM):** RNN architecture capable of learning long-term dependencies.\n",
    "18. **Gated Recurrent Unit (GRU):** RNN variant with gating mechanisms for efficient learning.\n",
    "19. **Autoencoder:** Neural network used for unsupervised learning of efficient data representations.\n",
    "20. **Variational Autoencoder (VAE):** Generative model that learns latent variables in data.\n",
    "21. **Generative Adversarial Network (GAN):** Framework for training generative models via adversarial training.\n",
    "22. **Transformer:** Model architecture relying entirely on self-attention mechanism.\n",
    "23. **BERT (Bidirectional Encoder Representations from Transformers):** Pretrained transformer model for natural language understanding.\n",
    "24. **GPT (Generative Pretrained Transformer):** Transformer-based model for autoregressive language generation.\n",
    "25. **Sequence-to-Sequence Model:** Neural network model for mapping input sequences to output sequences.\n",
    "26. **Attention Mechanism:** Mechanism focusing on relevant parts of input data for better learning.\n",
    "27. **Reinforcement Learning:** Learning paradigm where agents learn to make decisions through trial and error.\n",
    "28. **Q-Learning:** Model-free reinforcement learning algorithm for learning optimal policies.\n",
    "29. **Deep Q-Learning:** Extends Q-learning using deep neural networks for value function approximation.\n",
    "30. **Policy Gradient Methods:** Reinforcement learning methods optimizing policies through gradient ascent.\n",
    "31. **Actor-Critic:** Combines policy gradient (actor) and value-based (critic) methods for reinforcement learning.\n",
    "32. **Proximal Policy Optimization (PPO):** Proximal policy gradient method for stable reinforcement learning.\n",
    "33. **Deep Deterministic Policy Gradient (DDPG):** Actor-critic method for continuous action spaces in RL.\n",
    "34. **Soft Actor-Critic:** Off-policy actor-critic deep RL algorithm for stochastic policies.\n",
    "35. **Twin Delayed Deep Deterministic Policy Gradient (TD3):** Variant of DDPG for improved stability.\n",
    "36. **Monte Carlo Tree Search (MCTS):** Search algorithm used in decision processes, often in games.\n",
    "37. **Bayesian Optimization:** Sequential model-based optimization strategy using Bayesian inference.\n",
    "38. **Gaussian Process:** Probabilistic model for representing distributions over functions.\n",
    "39. **Hidden Markov Model (HMM):** Statistical model for sequences of observable events.\n",
    "40. **Conditional Random Field (CRF):** Discriminative undirected probabilistic graphical model.\n",
    "41. **Markov Decision Process (MDP):** Framework for decision-making where outcomes are partly random.\n",
    "42. **Particle Filter:** Sequential Monte Carlo method for filtering based on observed data.\n",
    "43. **Kalman Filter:** Recursive estimator using a series of measurements to estimate unknown variables.\n",
    "44. **Time Series Forecasting:** Predicting future values based on past data points.\n",
    "45. **Anomaly Detection:** Identifying outliers or rare events in data.\n",
    "46. **Recommendation System:** Predicting user preferences or item relevance.\n",
    "47. **Collaborative Filtering:** Recommendation technique based on user-item interactions.\n",
    "48. **Content-Based Filtering:** Recommends items based on their features.\n",
    "49. **Matrix Factorization:** Decomposes a matrix into product of matrices to capture latent factors.\n",
    "50. **Factorization Machine:** Model that captures interactions between features using factorization.\n",
    "\n",
    "Explore these concepts to build a solid foundation in machine learning and data science!\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
